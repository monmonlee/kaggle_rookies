{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Contents of This Notebook\n",
    "\n",
    "1. Import necessary libraries and read data from files.\n",
    "2. Preprocessing\n",
    "3. Baseline Model\n",
    "4. XGBoost Model with Time-Series Awareness\n",
    "\n",
    "Note that exploratory data analysis is in eda.ipynb, done by teammate Xueying Ng."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Import necessary libraries and read data from files."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import necessary libraries\n",
    "# BASE\n",
    "# ------------------------------------------------------\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "import gc\n",
    "import warnings\n",
    "\n",
    "# PACF - ACF\n",
    "# ------------------------------------------------------\n",
    "import statsmodels.api as sm\n",
    "\n",
    "# DATA VISUALIZATION\n",
    "# ------------------------------------------------------\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import plotly.express as px\n",
    "\n",
    "\n",
    "# CONFIGURATIONS\n",
    "# ------------------------------------------------------\n",
    "pd.set_option('display.max_columns', None)\n",
    "pd.options.display.float_format = '{:.2f}'.format\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/Users/chloeyueh/Documents/git-repos/kaggle_rookies/competition-data/test.csv\n",
      "/Users/chloeyueh/Documents/git-repos/kaggle_rookies/competition-data/train.csv\n",
      "/Users/chloeyueh/Documents/git-repos/kaggle_rookies/competition-data/transactions.csv\n",
      "/Users/chloeyueh/Documents/git-repos/kaggle_rookies/competition-data/oil.csv\n",
      "/Users/chloeyueh/Documents/git-repos/kaggle_rookies/competition-data/holidays_events.csv\n",
      "/Users/chloeyueh/Documents/git-repos/kaggle_rookies/competition-data/sample_submission.csv\n",
      "/Users/chloeyueh/Documents/git-repos/kaggle_rookies/competition-data/stores.csv\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "for dirname, _, filenames in os.walk('/Users/chloeyueh/Documents/git-repos/kaggle_rookies/competition-data'):\n",
    "    for filename in filenames:\n",
    "        print(os.path.join(dirname, filename))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read the data from all the files and keeping it for future use\n",
    "train = pd.read_csv('/Users/chloeyueh/Documents/git-repos/kaggle_rookies/competition-data/train.csv')\n",
    "test = pd.read_csv('/Users/chloeyueh/Documents/git-repos/kaggle_rookies/competition-data/test.csv')\n",
    "stores = pd.read_csv('/Users/chloeyueh/Documents/git-repos/kaggle_rookies/competition-data/stores.csv')\n",
    "transactions = pd.read_csv('/Users/chloeyueh/Documents/git-repos/kaggle_rookies/competition-data/transactions.csv')\n",
    "oil = pd.read_csv('/Users/chloeyueh/Documents/git-repos/kaggle_rookies/competition-data/oil.csv')\n",
    "holidays = pd.read_csv('/Users/chloeyueh/Documents/git-repos/kaggle_rookies/competition-data/holidays_events.csv')\n",
    "sample = pd.read_csv('/Users/chloeyueh/Documents/git-repos/kaggle_rookies/competition-data/sample_submission.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Preprocessing\n",
    "\n",
    "This step involves processing training and testing data in the same way using <code>process_data</code> function, and actively making sure that the one-hot encoded columns match.\n",
    "\n",
    "**Functions in this step**\n",
    "\n",
    "<code>adjust_holidays</code> adjusts holidays according to the following steps:\n",
    "- By default all rows are marked as holidays (is_real_holiday=1)\n",
    "- If transferred is True but type is not 'Transfer', it is assumed that the date is not actually a holiday and is set to 0\n",
    "- Set type 'Work Day' to 0 (non-holiday)\n",
    "\n",
    "<code>process_data</code> integrates and preprocesses data:\n",
    "- Filter data based on specified date range\n",
    "- Merge stores, oil and holidays data into the main data set\n",
    "- Forward filling of missing values ​​for crude oil price (assuming field name 'dcoilwtico')\n",
    "- Create binary holiday token is_holiday based on holidays data, using adjusted is_real_holiday\n",
    "- Added salary payment indicator (is_payday): If the date is the 15th or the end of the month, it will be marked as 1\n",
    "- One-hot encoding of product families\n",
    "    \n",
    "**函式**\n",
    "\n",
    "<code>adjust_holidays</code> 根據說明調整假日資料（<code>holidays</code>）：\n",
    "- 預設所有行均標記為假日 (is_real_holiday=1)\n",
    "- 如果 transferred 為 True，但 type 不是 'Transfer'，則認為該日期實際上不是慶祝假日，設為 0\n",
    "- 將 type 為 'Work Day' 的設為 0（非假日）\n",
    "\n",
    "\n",
    "<code>process_data</code> 整合並預處理數據（<code>train</code>、<code>test</code>）：\n",
    "- 根據指定日期範圍過濾數據\n",
    "- 合併 stores、oil 與 holidays 資料到主數據集\n",
    "- 前向填充原油價格缺失值 (假設欄位名稱 'dcoilwtico')\n",
    "- 根據 holidays 資料創建二進制假日標記 is_holiday，採用經過調整的 is_real_holiday\n",
    "- 新增薪資發放指標 (is_payday)：若該日期為 15 號或月末，則標記為 1\n",
    "- 對產品家族進行 one-hot 編碼"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(3054348, 45)\n",
      "(28512, 44)\n"
     ]
    }
   ],
   "source": [
    "def adjust_holidays(holidays_df):\n",
    "    holidays_df = holidays_df.copy()\n",
    "    holidays_df['is_real_holiday'] = 1\n",
    "    holidays_df.loc[(holidays_df['transferred'] == True) & (holidays_df['type'] != 'Transfer'), 'is_real_holiday'] = 0\n",
    "    holidays_df.loc[holidays_df['type'] == 'Work Day', 'is_real_holiday'] = 0\n",
    "    return holidays_df\n",
    "\n",
    "def process_data(df, stores, oil, holidays, start_date=None, end_date=None):\n",
    "    # 日期格式處理\n",
    "    df['date'] = pd.to_datetime(df['date'])\n",
    "    oil['date'] = pd.to_datetime(oil['date'])\n",
    "    holidays['date'] = pd.to_datetime(holidays['date'])\n",
    "\n",
    "    # 日期範圍過濾（只對訓練資料可能有意義）\n",
    "    if start_date:\n",
    "        df = df[df['date'] >= pd.to_datetime(start_date)]\n",
    "    if end_date:\n",
    "        df = df[df['date'] <= pd.to_datetime(end_date)]\n",
    "\n",
    "    # 合併商店資訊\n",
    "    df = pd.merge(df, stores, on='store_nbr', how='left')\n",
    "\n",
    "    # 合併油價\n",
    "    df = pd.merge(df, oil, on='date', how='left')\n",
    "    if 'dcoilwtico' in df.columns:\n",
    "        df['dcoilwtico'] = df['dcoilwtico'].fillna(method='ffill')\n",
    "\n",
    "    # 假日處理\n",
    "    holidays_adj = adjust_holidays(holidays)\n",
    "    holidays_sel = holidays_adj[['date', 'is_real_holiday']]\n",
    "    df = pd.merge(df, holidays_sel, on='date', how='left')\n",
    "    df['is_real_holiday'] = df['is_real_holiday'].fillna(0)\n",
    "    df.rename(columns={'is_real_holiday': 'is_holiday'}, inplace=True)\n",
    "\n",
    "    # 薪資日（每月 15 號和月末）\n",
    "    df['is_payday'] = ((df['date'].dt.day == 15) | (df['date'].dt.is_month_end)).astype(int)\n",
    "\n",
    "    # One-hot 編碼 product family（先記住有哪些 family）\n",
    "    df = pd.get_dummies(df, columns=['family'], prefix='family')\n",
    "\n",
    "    return df\n",
    "\n",
    "# 使用 process_data() 處理訓練數據，指定日期範圍（根據需要調整）\n",
    "processed_train = process_data(train, stores, oil, holidays, start_date='2013-01-01', end_date='2017-08-15')\n",
    "processed_test = process_data(test, stores, oil, holidays)\n",
    "\n",
    "# Check dataframe shapes -- not necessary\n",
    "print(processed_train.shape)\n",
    "print(processed_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Ensure One-Hot Columns Match** \n",
    "\n",
    "Make sure both processed_train and processed_test have the same family columns."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get all family columns from training set\n",
    "train_fam_cols = [col for col in processed_train.columns if col.startswith('family_')]\n",
    "\n",
    "# Get all family columns from test set\n",
    "test_fam_cols = [col for col in processed_test.columns if col.startswith('family_')]\n",
    "\n",
    "# Find missing columns in test\n",
    "missing_in_test = list(set(train_fam_cols) - set(test_fam_cols))\n",
    "\n",
    "# Add missing columns with 0s\n",
    "for col in missing_in_test:\n",
    "    processed_test[col] = 0\n",
    "\n",
    "# Reorder test columns to match train and exclude sales column\n",
    "processed_test = processed_test[processed_train.columns.drop('sales')]  # exclude sales\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Set Up a Baseline Model (Mean Sales Per Store-Family)\n",
    "This model will predict the average sales for each (store_nbr, family) pair in the training data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Group by store and family to get the mean sales\n",
    "store_family_mean = train.groupby(['store_nbr', 'family'])['sales'].mean().reset_index()\n",
    "store_family_mean.columns = ['store_nbr', 'family', 'mean_sales']\n",
    "\n",
    "# Merge the mean with test data\n",
    "baseline_preds = pd.merge(test, store_family_mean, on=['store_nbr', 'family'], how='left')\n",
    "\n",
    "# Fill missing means with global mean if any (e.g., new store-family combos)\n",
    "global_mean = train['sales'].mean()\n",
    "baseline_preds['mean_sales'] = baseline_preds['mean_sales'].fillna(global_mean)\n",
    "\n",
    "# Prepare submission\n",
    "submission = baseline_preds[['id']].copy()\n",
    "submission['sales'] = baseline_preds['mean_sales']\n",
    "\n",
    "# Export to CSV\n",
    "submission.to_csv('baseline_submission.csv', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
